# Алгоритм многоэтапной генерации документации через LLM

## Обзор

Данный документ описывает процесс многоэтапной генерации документации для узлов графа кода с использованием больших языковых моделей (LLM). Процесс состоит из нескольких этапов, каждый из которых решает свою задачу и обогащает документацию для разных аудиторий.

## Архитектура

Система использует **двухэтапный подход** (с возможностью расширения до трёх этапов):

1. **Coder** (техническое объяснение) - генерирует детальное техническое описание кода для разработчиков
2. **Speaker/Talker** (человекочитаемый пересказ) - переписывает техническое описание в понятный для нетехнических специалистов формат

**Планируемый этап**:
3. **Instruct** (инструкции по использованию) - генерирует практические инструкции, примеры использования и предупреждения

## Инструменты

- **OllamaCoderClient** - клиент для генерации технических объяснений
- **OllamaTalkerClient** - клиент для переписывания в человекочитаемый формат
- **ExplainRequestFactory** - фабрика для создания запросов к LLM
- **RawContentFillerScheduler** - планировщик для заполнения `content_raw` (coder этап)
- **ContentFillerScheduler** - планировщик для заполнения `content` (speaker этап)

## Этап 1: Coder - Техническое объяснение

### Назначение

Генерация детального технического описания кода для разработчиков. Описание включает:
- Назначение и высокоуровневое поведение
- Параметры, возвращаемый тип, инварианты, пред/пост-условия
- Шаги алгоритма и сложность
- Побочные эффекты, исключения, заметки о потокобезопасности
- Важные зависимости и как они используются
- Граничные случаи и режимы отказа
- Краткий пример использования (Kotlin)
- Для endpoint/listener/job - описание входных/выходных данных и идемпотентности
- Для тестов - сценарий и что проверяется

### Процесс

#### Шаг 1.1: Планировщик находит чанки для обработки

**Сервис**: `RawContentFillerScheduler.pollAndFill()`

```kotlin
@Scheduled(fixedDelayString = "${docgen.fill.poll-ms:4000}")
fun pollAndFill() {
    val batch = tx.execute { 
        chunkRepo.lockNextBatchForRawFill(batchSize) 
    } ?: return
    
    // Обработка батча...
}
```

**Критерии отбора**:
- Чанк имеет `content_raw == null` или пустой
- Чанк связан с узлом, у которого есть исходный код (`node.sourceCode != null`)
- Чанк не заблокирован другим воркером

#### Шаг 1.2: Создание запроса для LLM

**Фабрика**: `ExplainRequestFactory.toCoderExplainRequest()`

```kotlin
fun Chunk.toCoderExplainRequest(): CoderExplainRequest {
    val node = this.node
    val lang = langDetected ?: node.lang.name.lowercase()
    val codeExcerpt = node.sourceCode!!.trim()
    val hints = buildRichHints(this, node).ifBlank { null }
    
    return CoderExplainRequest(
        nodeFqn = this.title?.takeIf { it.isNotBlank() } ?: node.fqn,
        language = lang,
        hints = hints,
        codeExcerpt = codeExcerpt,
        lineStart = node.lineStart,
        lineEnd = node.lineEnd,
    )
}
```

**Структура CoderExplainRequest**:
- `nodeFqn` - полное квалифицированное имя узла
- `language` - язык программирования (kotlin, java, etc.)
- `hints` - обогащённые подсказки из метаданных узла
- `codeExcerpt` - фрагмент исходного кода
- `lineStart`, `lineEnd` - диапазон строк в исходнике

#### Шаг 1.3: Построение обогащённых подсказок (hints)

**Метод**: `ExplainRequestFactory.buildRichHints()`

Подсказки включают:

1. **Базовая информация**:
   - `Kind` - тип узла (CLASS, METHOD, etc.)
   - `Package` - пакет
   - `Owner` - владелец (для вложенных классов)
   - `File` - путь к файлу
   - `Span` - диапазон строк

2. **Сигнатуры и типы**:
   - `Signature` - сигнатура метода/класса
   - `Params` - параметры
   - `ReturnType` - возвращаемый тип
   - `Supertypes` - супертипы (наследование/реализация)

3. **Аннотации и модификаторы**:
   - `Annotations` - список аннотаций
   - `Modifiers` - модификаторы доступа и другие

4. **KDoc**:
   - `KDoc-Summary` - краткое описание из KDoc
   - `KDoc-Details` - детальное описание (первые 300 символов)

5. **Импорты** (первые 8):
   - `Imports` - список импортов

6. **Контекст пайплайна**:
   - `Chunking-Strategy` - стратегия разбиения
   - `Audience` - целевая аудитория
   - `Goal` - цель генерации
   - `QualityTarget` - целевое качество

7. **Эвристики по роли**:
   - Определение тестового контекста
   - Определение HTTP endpoint (аннотации `@*Mapping`)
   - Определение scheduled job (аннотации `@Scheduled`)
   - Определение Kafka listener (аннотации `@KafkaListener`)

8. **Граф-подсказки по вызовам**:
   - `Calls-IntraClass` - количество внутренних вызовов
   - `Calls-External` - количество внешних вызовов
   - Примеры вызовов (первые 5)

9. **Инструкции для LLM**:
   - Структурированный список требований к ответу

#### Шаг 1.4: Генерация через LLM

**Клиент**: `OllamaCoderClient.explain()`

```kotlin
fun explain(req: CoderExplainRequest): String {
    val userMessage = buildUserMessage(req)
    
    val result = chat
        .prompt()
        .system(SYSTEM_PROMPT)
        .user(userMessage)
        .call()
        .content()
    
    return result.orEmpty().trim()
}
```

**System Prompt** (OllamaCoderClient):
```
Ты — опытный Senior Developer и IT-архитектор.
Объясняй код строго по фактам из запроса. Пиши на РУССКОМ.

ПРАВИЛА:
- Не придумывай отсутствующие детали/зависимости/поля.
- Если данных мало — прямо скажи, чего не хватает.
- Соблюдай формат Markdown и заголовки строго как ниже.
- Не повторяй одно и то же в разных разделах.
- Если фрагмент пуст или неинформативен — дай краткое описание ограничений.

СТРУКТУРА ОТВЕТА:
### 1. Краткое описание
### 2. Основная логика
### 3. Контекст и связи

ФОРМАТИРОВАНИЕ:
- Кодовые примеры — только в бэктиках ```kotlin.
- Не вставляй импортов в примеры, если это не критично для понимания.
- Списки держи компактными (≤7 пунктов).
```

**User Message** включает:
- Язык программирования
- Расположение (FQN) и диапазон строк
- Подсказки (hints) из метаданных
- Фрагмент кода в блоке ```kotlin

#### Шаг 1.5: Языковая валидация и перегенерация

**Логика**: `RawContentFillerScheduler` проверяет долю кириллицы в ответе

```kotlin
var answer = coder.explain(req)
var regen = 0

// ЯЗЫКОВОЙ ФИЛЬТР → перегенерация при необходимости
while (!LangGuards.isRussianEnough(answer, minCyrRatio) && regen < maxRegens) {
    regen++
    val reinforcedReq = req.copy(
        hints = (req.hints ?: "") + 
            "\nТребование: Ответ ДОЛЖЕН быть на РУССКОМ языке. Используй кириллицу."
    )
    Thread.sleep((500L * regen).coerceAtMost(1500L))
    answer = coder.explain(reinforcedReq)
}
```

**Параметры**:
- `minCyrRatio` (по умолчанию 0.6) - минимальная доля кириллицы
- `maxRegens` (по умолчанию 2) - максимальное количество перегенераций

#### Шаг 1.6: Сохранение результата

```kotlin
val sha = sha256(answer)
val updated = tx.execute {
    chunkRepo.trySetRawContent(
        id = chunk.id!!,
        content = answer,
        updatedAt = OffsetDateTime.now(),
    )
} ?: 0
```

**Оптимистическая блокировка**: Используется `trySetRawContent` для избежания конфликтов при параллельной обработке.

**Результат**: Сохранение в `chunk.content_raw` (техническое объяснение на русском языке).

## Этап 2: Speaker/Talker - Человекочитаемый пересказ

### Назначение

Переписывание технического описания в понятный для нетехнических специалистов (менеджеров, аналитиков) формат. Описание фокусируется на:
- **Что** делает компонент (бизнес-задача, роль в процессе)
- **Не как** он это делает (детали реализации скрыты)

### Процесс

#### Шаг 2.1: Планировщик находит чанки для обработки

**Сервис**: `ContentFillerScheduler.pollAndFill()`

```kotlin
fun pollAndFill() {
    val batch = tx.execute { 
        chunkRepo.lockNextBatchContentForFill(batchSize) 
    } ?: return
    
    // Обработка батча...
}
```

**Критерии отбора**:
- Чанк имеет заполненный `content_raw` (результат coder этапа)
- Чанк имеет пустой или устаревший `content`
- Чанк не заблокирован другим воркером

#### Шаг 2.2: Создание запроса для LLM

**Фабрика**: `ExplainRequestFactory.toTalkerRewriteRequest()`

```kotlin
fun Chunk.toTalkerRewriteRequest(): TalkerRewriteRequest {
    val lang = this.langDetected ?: this.node.lang.name
    return TalkerRewriteRequest(
        nodeFqn = this.title ?: this.node.fqn,
        language = lang,
        rawContent = this.contentRaw ?: throw RuntimeException("Нет содержимого для объяснения"),
    )
}
```

**Структура TalkerRewriteRequest**:
- `nodeFqn` - полное квалифицированное имя узла
- `language` - язык программирования
- `rawContent` - техническое описание из `content_raw` (результат coder этапа)

#### Шаг 2.3: Генерация через LLM

**Клиент**: `OllamaTalkerClient.rewrite()`

```kotlin
fun rewrite(req: TalkerRewriteRequest): String {
    val userPrompt = buildString {
        appendLine("### Контекст (для твоего понимания)")
        appendLine("Компонент: ${req.nodeFqn}")
        appendLine("Язык: ${req.language}")
        appendLine()
        appendLine("### Техническое описание (источник для пересказа):")
        appendLine(req.rawContent.trim())
    }
    
    val rawResult = chat
        .prompt()
        .system(rewriteSystemPrompt)
        .user(userPrompt)
        .call()
        .content()
    
    // Удаление служебных тегов мышления
    return thinkRegex.matcher(rawResult.orEmpty()).replaceAll("").trim()
}
```

**System Prompt** (OllamaTalkerClient):
```
Твоя задача — переписать техническое описание компонента системы 
(класса, метода или процесса), сделав его понятным для нетехнического 
специалиста (менеджера или аналитика).

### Цель
Опиши, *что* этот компонент делает (его бизнес-задачу или роль в процессе), 
а не *как* он это делает (детали реализации).

### Основные правила
1. **Пиши простым языком:** Представь, что объясняешь коллеге, который не знает код.
2. **По существу:** Сохрани основную суть. Не додумывай и не добавляй факты, которых нет в источнике.
3. **Полнота и краткость:** Пиши кратко, но достаточно для полного понимания бизнес-задачи.

### КРИТИЧЕСКИ ВАЖНЫЕ ПРАВИЛА (ЯЗЫК И ФОРМАТ)

4. **ТОЛЬКО РУССКИЙ ЯЗЫК И БЕЗ ЖАРГОНА:**
   * Весь твой ответ должен быть **на чистом русском языке**.
   * **КАТЕГОРИЧЕСКИ ЗАПРЕЩЕНО:** Смешивать языки.
   * **КАТЕГОРИЧЕСКИ ЗАПРЕЩЕНО (ЖАРГОН):** Не используй имена классов, имена полей, 
     интерфейсов или IT-термины из источника.
   * **ЗАМЕНЯЙ:** Заменяй жаргон общими понятиями.
   * **ИСКЛЮЧЕНИЕ:** Можешь использовать общепринятые аббревиатуры (API, JSON, SQL) 
     или названия технологий (Spring, Gradle), *только* если их невозможно адекватно 
     перевести или заменить общим понятием.

5. **НИКАКИХ ОБДУМЫВАНИЙ (ЧИСТЫЙ ОТВЕТ):**
   * Твой ответ должен содержать *только* итоговый переписанный текст.
   * **КАТЕГОРИЧЕСКИ ЗАПРЕЩЕНО:** Использовать теги `<think>` или 
     `</think>`, описывать свой процесс мышления, добавлять вступления 
     ("Вот переписанный текст:") или любой другой служебный текст.
```

**Очистка ответа**: Удаление тегов `<think>...</think>` через регулярное выражение.

#### Шаг 2.4: Сохранение результата

```kotlin
tx.execute {
    val reloaded = chunkRepo.findById(chunk.id!!).orElse(null) ?: return@execute
    reloaded.content = answer
    reloaded.updatedAt = OffsetDateTime.now()
    chunkRepo.save(reloaded)
}
```

**Результат**: Сохранение в `chunk.content` (человекочитаемое описание на русском языке без IT-жаргона).

## Этап 3: Instruct - Инструкции по использованию (планируемый)

### Назначение

Генерация практических инструкций по использованию компонента:
- Примеры использования
- Типичные сценарии
- Предупреждения и подводные камни
- Best practices

### Планируемая реализация

Этап будет использовать результат coder этапа для генерации инструкций. Входные данные:
- Техническое описание из `content_raw`
- Контекст из графа (связи, зависимости)
- Примеры использования из связанных узлов

## Конфигурация LLM клиентов

### Coder Client

**Конфигурация** (`application.yml`):
```yaml
ai:
  clients:
    coder:
      model: qwen2.5-coder:14b
      temperature: 0.3
      topP: 0.9
      seed: 42
```

**Характеристики**:
- Модель: `qwen2.5-coder:14b` (специализированная модель для кода)
- Низкая температура (0.3) - для детального и точного объяснения
- Фиксированный seed (42) - для воспроизводимости

### Talker Client

**Конфигурация** (`application.yml`):
```yaml
ai:
  clients:
    talker:
      model: qwen2.5:14b-instruct
      temperature: 0.7
      topP: 0.95
      seed: 42
```

**Характеристики**:
- Модель: `qwen2.5:14b-instruct` (инструкционная модель)
- Средняя температура (0.7) - для более естественного пересказа
- Фиксированный seed (42) - для воспроизводимости

## Структура данных

### Chunk после обработки

```kotlin
data class Chunk(
    // ... другие поля ...
    
    // Этап 1: Coder
    val contentRaw: String?,      // Техническое объяснение (Markdown)
    
    // Этап 2: Speaker/Talker
    val content: String,          // Человекочитаемое описание (Markdown)
    
    // Метаданные
    val langDetected: String?,    // Определённый язык (ru, en, etc.)
    val explainMd: String?,        // Дополнительное объяснение (если нужно)
    val explainQuality: Map<String, Any>, // Метрики качества
    // ...
)
```

## Оптимизации

1. **Батчевая обработка**: Обработка чанков батчами для эффективного использования ресурсов
2. **Оптимистическая блокировка**: Использование `trySetRawContent` для избежания конфликтов
3. **Языковая валидация**: Автоматическая перегенерация при недостаточной доле кириллицы
4. **Планировщики**: Асинхронная обработка через Spring `@Scheduled`
5. **Транзакционность**: Использование `TransactionTemplate` для атомарности операций

## Обработка ошибок

1. **Ошибка генерации**: Логируется, чанк остаётся в очереди для повторной обработки
2. **Пустой код**: Чанк пропускается с предупреждением
3. **Языковая валидация**: Автоматическая перегенерация до `maxRegens` раз
4. **Конфликты блокировки**: Чанк пропускается, обрабатывается другим воркером

## Схема потока данных

```
Chunk (content_raw = null, content = null)
  ↓
RawContentFillerScheduler.pollAndFill()
  ├─→ Загрузка батча чанков (lockNextBatchForRawFill)
  └─→ Для каждого чанка:
      ├─→ ExplainRequestFactory.toCoderExplainRequest()
      │   ├─→ Извлечение кода из node.sourceCode
      │   └─→ Построение hints из метаданных
      │
      ├─→ OllamaCoderClient.explain()
      │   ├─→ System Prompt (техническое объяснение)
      │   ├─→ User Message (код + hints)
      │   └─→ Генерация ответа
      │
      ├─→ Языковая валидация (LangGuards.isRussianEnough)
      │   └─→ Перегенерация при необходимости (до maxRegens)
      │
      └─→ Сохранение в chunk.content_raw
          ↓
Chunk (content_raw = "техническое объяснение", content = null)
  ↓
ContentFillerScheduler.pollAndFill()
  ├─→ Загрузка батча чанков (lockNextBatchContentForFill)
  └─→ Для каждого чанка:
      ├─→ ExplainRequestFactory.toTalkerRewriteRequest()
      │   └─→ Извлечение content_raw
      │
      ├─→ OllamaTalkerClient.rewrite()
      │   ├─→ System Prompt (человекочитаемый пересказ)
      │   ├─→ User Message (техническое описание)
      │   └─→ Генерация ответа
      │
      └─→ Сохранение в chunk.content
          ↓
Chunk (content_raw = "техническое объяснение", 
       content = "человекочитаемое описание")
```

## Использование результатов

### Для разработчиков

Используется `chunk.content_raw`:
- Детальное техническое описание
- Сигнатуры, параметры, возвращаемые типы
- Алгоритмы, сложность, потокобезопасность
- Примеры использования на Kotlin

### Для нетехнических специалистов

Используется `chunk.content`:
- Понятное описание бизнес-задачи
- Роль компонента в процессе
- Без IT-жаргона и технических деталей

### В RAG системе

Оба поля используются для:
- **Векторный поиск**: Поиск релевантных чанков по семантическому сходству
- **Полнотекстовый поиск**: Поиск по `contentTsv` (tsvector)
- **Контекстное обогащение**: Использование обоих описаний для разных аудиторий

## Связанные компоненты

- `OllamaCoderClient` - генерация технических объяснений
- `OllamaTalkerClient` - переписывание в человекочитаемый формат
- `ExplainRequestFactory` - создание запросов к LLM
- `RawContentFillerScheduler` - планировщик для coder этапа
- `ContentFillerScheduler` - планировщик для speaker этапа
- `LangGuards` - валидация языка (доля кириллицы)
- `ChunkRepository` - доступ к БД с оптимистической блокировкой

